
\documentclass[10pt,letterpaper]{article}
%\usepackage[top=0.85in,left=1.25in,footskip=0.75in]{geometry}

% line numbers
\usepackage{lineno}
\linenumbers

\usepackage{xcolor}


\begin{document}

\subsection*{Reviewers Comments}

Reviewer #1 (Remarks to the Author): 

\newline
Burroughs et al. presented a highly interesting study on the neural representation of word sequences. Using new speech materials, the experiment demonstrates that previous models (e.g., Ding et al., Nature Neuroscience 2016; Frank & Yang, PLoS One 2017) on neural tracking of speech may need to be revised. 
\newline
\noindent
1. For the grammatical two-word phrases used in the PM condition, some phrases were quite rare, e.g., "cold rat", "from fame", "fish make", and "solve less". I wonder if the listeners understood these rare phrases when listening to the isochronously presented speech. Even if they understood all the words, I wonder if they grouped them into phrases. Also, sometimes 4 words can form a larger phrase which is nonsense, e.g., "want fame from rice", which may discourage the listeners from grouping words into phrases. I think these points need discussion. 

\color{blue}
We agree with the reviewer here that the grouping of some of the two word phrases into longer word phrases is a minor issue in the current study, however the nature of the stimuli made it unavoidable so we tried to make them as rare as possible. This can be verified on the basis of a full list of experimental material provided in the Supplementary Information.
\newline
\noindent
\color{black}
Also, I suggest to do some quick behavioral tests. For example, recruit a couple of subjects and play a couple of trials to them. Ask them to do the same task described in the manuscript but give them a few unexpected structure-related questions after a critical trial, e.g., "did the words you hear form any phrase?" or "did you detect any pattern in the word sequence that you just heard?" etc. Alternatively, after a trial, ask the subjects to recall as many words as possible. I guess they can recall more A+N pairs and may not recall the PM condition very well and may actually recall some single words instead of pairs.
\color{blue}
\newline
\indent
Inline with reviewer 1’s suggestion to carry out some quick behavioural tests we have run an online study to look at whether recall was better for the AN condition compared to MP condition. We recruited 90 subjects and played them a reduced version of the experiment that contained four trials from each of the AN, MP and RR conditions. Trials were played in a random order, except for the final trial which was manipulated so that a similar number of participants were played a trial from each of the three conditions as the final trial. The attention trap was the same as in our EEG experiment. We asked the participants to write down as many things as they could remember from the last trial. We then compared how many words and phrases the subjects were able to remember following each of the conditions. The results from this study have been discussed on page 9 (and highlighted in blue), but briefly, this behavioural experiment demonstrated the difficulty in parsing the stimulus as it is being listened too and does indicate that the MP trials are harder to distinguish from RR than the AN trials. 
We have included details of the methods in the Methods section on page 14 under the subsection 'Behavioural Experiment'. Following publication all data and analysis scripts will be made freely available in accordance with our ethics.

\color{black}
\newline
\noindent
2. The Fourier analysis: Based on Fig. 2 and Fig. 3, it is clear that there is power leakage in the spectrum and therefore sometimes the spectral peak is "broad". The reason is that the duration of a phrase is 0.64 s while the sampling rate is 25 Hz, and therefore each phrase does not contain an integer number of samples. If the authors change the sampling rate to, e.g., 16 Hz, the spectrum will have sharper peaks. If all power concentrate in the same frequency bin, it gives a better chance to observe a significant result. Also, it also saves the readers from wondering why the peaks are sometimes broad and sometimes narrow.
\color{blue}
We believe this to be a misunderstanding. We have performed low pass filtering at 25 Hz, as has been done before when analysing these kinds of data (see Ding et al., 2015, 2017), but this does not make a significant difference to the ITPC or the sharpness of the peaks. Our data was sampled at 1000 Hz and we performed the Fourier analysis on the data from each trial with a duration of 16.64 s. This meant that there was a specific frequency bin for the phrase and syllable rates at 1.5625 and 3.125 Hz respectively.

It remains unclear to us as to why there does appear to be some variation in the breadth of the spectral peaks across trials and participants. It could be possible that despite the isochronous presentation of syllables, differences in the acoustics of the syllable onset yielded a slight jitter to the isochrony (as perceived by the participants).

\color{black}
\newline
\noindent
3. I didn't find which EEG channel is being analyzed. If the results are averaged over channels, some responses that are only observable in a small number of channels may be missed. Showing the response topography will also help.
\color{blue}
Our results show the results averaged over channels. Studies before ours have also reported the data averaged across electrodes although some have seen and included topographical distributions in addition to these results, as suggested by reviewer 1 (\cite{DingEtAl2016, DingEtAl2017}). Unfortunately we did not observe consistent topographic effects and have therefore reported our results averages over all channels. Using ITPC instead of power helps to improve our signal to noise ratio, as we address in response to reviewer 2’s comment below.
\color{black}
\newline
\noindent
 In Fig. 3, it's hard to see the black line on top of the dark blue lines. Making the blue lines lighter will help.
 \color{blue}
We have now changed figure 3 so that the blue lines are lighter. 

\color{black}
\newline
\noindent
Reviewer #2 (Technical Comments to the Author): 

\newline
\noindent
Main concerns are statistical, but which could easily be addressed in a review round. For example, inference is performed based on the comparison between significant and non significant results; however, the difference between significant and non significant is not necessarily significant (Gelman and Stern, 2012). Instead, the difference must be tested directly.
\color{blue}
We agree with Reviewer 2 and have now performed a one-way ANOVA over the phrase and syllable peaks observed in each of the four conditions and included them in our results on page 4. The effect of condition was significant at the phrase frequency (F(3,57)=6.05, p=0.002). Planned pairwise comparisons between ITPC amplitudes at the phrase frequency revealed that the ITPC was significantly higher in the  AN condition than in each of the other three conditions (AN vs AV: p=0.024, AN vs. MP: p<0.001, AN vs. RR: p<0.001).The effect of condition was significant at the syllable frequency (F(3,57)=6.6, p<0.001), however none of the planned pairwise comparisons were significant  
\color{black}
\newline
\noindent
 Additionally, the inferential logic relies in part on null results, but null results in the frequentist framework are difficult to assess without a power analysis or at least a statement about expected effect sizes based on the previous literature.
\color{blue}
We have now included a statement about the expected effect size based on previous literature in the discussion. 

\color{black}
\newline
\noindent

Reviewer #2 (Remarks to the Author): 


\newline
\noindent

In this manuscript, the authors address a confound in previous work using the frequency tagging method to argue for the neurobiological reality of hierarchical structure building in language processing. Addressing this confound between the phrase rate and the lexical category rate potentially allows for distinguishing between the hierarchical-structure building account and an alternative account based on lexical co-occurences and transitional probabilities, as implemented in the distributional model word2vec. 


\newline
\noindent

Overall, I think that this manuscript does a good job addressing an unresolved debate in the literature. Unfortunately, some of my statistical points would apply below equally well to previous studies in this debate, but this should not hinder the authors from addressing them in their work. 
\newline
\noindent
Major points 
\newline
\noindent
The inference is performed based on the comparison between significant and non significant results; however, the difference between significant and non significant is not necessarily significant (Gelman and Stern, 2012). Instead, the difference must be tested directly. Additionally, the inferential logic relies in part on null results, but null results in the frequentist framework are difficult to assess without a statistical power analysis or at least a statement about expected effect sizes based on the previous literature. (Note that an observed power analysis won't help you here as that is just an alternative presentation of the observed significance patter, Hoenig and Heisey, 2001). Directly comparing pairwise difference in particular frequency bands would eliminate some of the reliance on null results. 
\color{blue}
We agree with Reviewer 2. We have discussed these issues above and agree that it is necessary to include the 1x4 ANOVA discussed above and followed by pairwise comparisons. We have now included a new paragraph in the results and a figure to describe them, as above 
\color{black}
\newline
\noindent
Why was only ITPC and not power used? In various papers from Ding and colleagues, evoked power also plays a critical role in the argumentation.
\color{blue}
ITPC was selected as we wanted to make a direct comparison with the most recent paper from Ding et al.2017. Although analysis of the results using evoked power showed the same pattern of result, our results are most clearly represented using ITPC as this significantly improves the signal to noise ratio.

\newline
\noindent
\color{black}
Given that the authors used ITPC and not power, does the location of the phrasal head in different types of phrases matter? If the phrasal head is what's driving alignment and thus phase coherence, does it matter that e.g. NPs have the head after the modifiers (that word) while VPs have their head before (send less)? How does this impact the claim that the "brain's response is not merely a function of lexical category; rather, it also reflects higher-level syntactic constituency" -- lexical category correlates with syntactic constituency here, because heads are restricted to particular lexical categories.
\color{blue}
We thank the reviewer for pointing this out; the headedness of the phrases can indeed be an important parameter for future research. Yet we believe that the main result of the present study (i.e. the difference between the AN and AV conditions) cannot be attributed to headedness. If headedness drove parsing, the AV stream could have been parsed as …VA-VA-VA-VA… which should have still yielded a phrase-rate response. The response was not observed, which suggests that the parser did not attempt to group words in the AV condition (either into AV or VA constituents). 
\newline
\noindent
\color{black}
Why is the simulated ITPC larger across non-critical frequency bands for AN and AV? This difference appears to be as big as the difference in the critical frequency bands.
\color{blue}
We thank the reviewer for flagging this up. We had made an error in this figure and included a greater number of trials when simulating the AN and AV conditions compared to the MP and RR conditions. We have now corrected this error and have updated the figure accordingly.
\color{black}
\newline
\noindent
Please do not present z-scores as stacked bar charts. These are hard to read and imply that syllables and phrases are additive and not orthogonal effects.
\color{blue}
We have now modified figure 4 so that the bars representing the phrase and syllable ITPC values are adjacent rather than on top of one another. Participant data is separated by a small gap.

\color{black}
\newline
\noindent
I liked seeing the comparison of the single-subject results to the grand average results. This is important. That said, this does raise some additional issues. For example, why do 4/20 participants show an effect for the AV condition? This is far more than would be expected under the null hypothesis.
\color{blue}
We appreciate this comment from Reviewer 2. It is possible that there is some random structure apparent within the RR stimuli at the phrase rate. This can be seen in the ITPC of the Frank vectors in Figure 2. It is possible that this is generating some of the significant ITPC responses observed in 4/20 participants, which is higher than expected under the null hypothesis.
It is also known that people may have a general tendency to group words in a random sequence into pairs (see, for example, in Getz 2018 Thompson & Newport, 2007), which may explain the presence of an above-chance ITPC at the phrase frequency in some participants.  Given this, an important point is that overall the ITPC at the phrase frequency is stronger in AN vs RR condition, both across participants and in terms of the number of individual participants.
\color{black}
\newline
\noindent
Why do "only" 13/20 show an effect for the AN condition, which should hold under both the hierarchical and distributional processing accounts?
\color{blue}
If we consider the ITPC values at the syllable frequency there are 2-3 subjects that do not show a significant response in each condition. Given that not all participants showed an above-chance response at the syllable frequency (at which the regularity is present in the physical input, i.e. the auditory stimulus), it is unsurprising that even more participants did not show an above-chance response at the phrase frequency. Alternatively there may be individual differences in language processing that underlie this finding.

\color{black}
\newline
\noindent
I realize that this information is not readily available from other studies using this technique and so it's not possible to compare the present results to past work. That said, the claims of subject-level prevalence can be made more rigorous via e.g. the minimum information statistic (Allefeld et al. 2016) and this would be a valuable contribution. 
On a related note, what happens when averaging is done across items instead of across subjects? This is perhaps too much for the main text, but would be a valuable supplemental analysis, especially given that the language-as-a-fixed-effect fallacy has been known since at least the 1970s. This could potentially also address concerns about the location of phrasal heads, if the distribution of different phrase types differed across items in the MP condition. 
/color{blue}
These are interesting and valuable remarks but that to implement them properly we believe that the analysis would have to be redone using a different method of examining phase coherence; the manner in which phase coherence is collapsed on a subject-by-subject basis to disguise differences in overall phase makes these other, more modern approaches, hard to apply. This is something we have already been thinking about and hope to develop further in the future, but it is beyond the scope of the current study.
\color{black}
\newline
\noindent
How were the frequency bands actually divided up? I couldn't find this in the manuscript. 
\color{blue}
The frequency resolution in our calculation of ITPC was 0.0651 and went from 0.2604 through to 3.9714. This meant that our frequencies of interest fell within the specific frequency bins of 1.5625 and 3.125 respectively. We have a statement in our paper at the beginning of the Data Analysis subsection of the Methods section that describes this frequency resolution.
\color{black}
\newline
\noindent
Why was 0.025 chosen as the significance threshold? This is equivalent to keeping p-values from a two-sided test when examining a one-sided difference. (Fixing this will also address the intertwined issue of the critical z value.) 
\color{blue} We apologise for this mistake, it does not make any difference to the presented results but this has now been corrected in the text to p=0.05. The critical z value is now 1.96.
\newline
\noindent
Please make all analysis scripts and if possible within the constraints of your ethical approval all data available.
\color{blue}
We will make sure these are available post-publication. Our consent allows for open-access and so we can make all analysis scripts freely available.
\color{black}
\newline
\noindent
How does the attentional task used here compare to the task(s) in the experiments from Ding and colleagues?
\color{blue}
In studies carried out by Ding and colleagues 2017, participants were asked to distinguish outlier trials from normal trials at the end of each trial. An outlier trial was defined as ‘the same as a normal trial except that 3 consecutive words from a roved position were replaced with 3 random words’. Therefore participants were asked to look for an absence of a four-word sentence or two-word phrase, whereas in ours they were asked to identify the presence of a four word phrase. The earlier 2016 paper by Ding and colleagues followed a similar format whereby outlier trials consisted of four randomly chosen English words that did not construct a sentence or a phrase.
\color{black}
\newline
\noindent
EEG recording: please report more information about the filters used, e.g. whether the hardware filter was used or the online software filter was used during recording as well as relevant filter specifications for digital filters (e.g. IIR vs. FIR, filter phase, filter length, etc.). Note that Brain Products specifies its lower filter edge in terms of a the analogue time constant (s), which is converted to frequency via 1/(2*pi*s). Please do the same for the offline lowpass filter. 
\color{blue}
We have added additional information regarding the EEG recording to the EEG recording subsection of the Methods section in the paper on page 12.
\color{black}
\newline
\noindent
Minor points 
\newline
\noindent
Given that Scientific Reports uses endnote citations and rather unfortunately de-emphasizes methods, the authors may wish to see how well local colleagues who are not familiar with this design follow the mansucript. I found the details of the inferences somewhat hard to follow in my first reading, but found it relatively straightforward after I had read the methods section. 
\newline
\noindent
p3,l68 "for each stimuli" -> "for each stimulus"
\color{blue}
I have now modified this typo
\color{black}
same paragraph: I'm not sure this is a completely felicitous description of Frank's work. 
\color{blue}
We have edited the text to read: 'For each trial 320 copies of the vector for each word in the trial are lined up side-by-side forming the columns of a matrix; each column representing 1 ms of the stimulus. The rows of this matrix is then treated as a EEG and this fictive signal is analysed in the same way as the real EEG signal is and the ITPC averaged over the result for each row, much as we average over individual electrodes.' on page 3.
\color{black}
\newline
\noindent
p9, l265: I am not aware of a valid "pronoun-noun" phrase in English.
\color{blue}
We have replaced with the correct version ‘preposition-noun’.
\color{black}
\newline
\noindent
p12, l353: This description of the p-value isn't correct. p-values are the probability under the null hypothesis of observing a value at least as extreme as the observed value. Note that it's not the probability of any particular value, but rather of a range of values, and that this statement is made *under the assumption of the null hypothesis*.
\color{blue}
We thank the reviewer for pointing out our mistake here. This has now been corrected.
\color{black}
\newline
\noindent
Ref [19]: you need to wrap acronyms in BibTeX with curly braces -- {MEG}, {EEG} -- to guarantee that they aren't made lowercase.
\color{blue}
This has now been corrected.




\end{document}